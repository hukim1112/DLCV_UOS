{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Logistic Regression (classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1) Logistic Regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Data Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data ( height and weight of  adults and children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of data to be created\n",
    "m = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_height = np.random.normal(175, 5, [m, 1])\n",
    "adult_weight = np.random.normal(70, 5, [m, 1])\n",
    "\n",
    "adult_dataset = np.concatenate( (adult_weight, adult_height) , axis = 1)\n",
    "\n",
    "print(adult_dataset.shape)\n",
    "print(adult_dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_height = np.random.normal(120, 5, [m, 1])\n",
    "child_weight = np.random.normal(30, 5, [m, 1])\n",
    "\n",
    "child_dataset = np.concatenate( (child_weight, child_height) , axis = 1)\n",
    "\n",
    "print(child_dataset.shape)\n",
    "print(child_dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(adult_dataset[:,0], adult_dataset[:,1], c=np.array([(1, 1, 0)]))\n",
    "ax1.scatter(child_dataset[:,0], child_dataset[:,1], c=np.array([(0, 1, 0)]))\n",
    "plt.title(\"The distribution of created dataset \")\n",
    "plt.xlabel(\"height x2\")\n",
    "plt.ylabel(\"weight x1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각각의 클레스에 대한 레이블을 만들어줍니다.\n",
    "# adult는 1로, child는 0으로 지정합니다.\n",
    "# binary classification은 내가 찾는 클래스(1)이냐 아니냐(0)를 분류합니다.\n",
    "# 즉 우리가 학습시킬 모델은 성인과 성인이 아닌 데이터를 분류하는 모델입니다.\n",
    "\n",
    "adult_label = np.ones( shape=[m, 1] )\n",
    "child_label = np.zeros( shape=[m, 1] )\n",
    "label = np.concatenate( (adult_label, child_label) )\n",
    "print('label의 shape' , label.shape)\n",
    "print(label[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data + Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset = np.concatenate((adult_dataset , child_dataset))\n",
    "total_dataset = np.concatenate( (total_dataset, label), axis = 1  )\n",
    "\n",
    "np.random.shuffle(total_dataset) # Shuffle dataset\n",
    "print(total_dataset[:10])\n",
    "print(total_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple scaling of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_mean= total_dataset[:, 0].mean()\n",
    "height_mean= total_dataset[:, 1].mean()\n",
    "total_dataset[:, 0] /= weight_mean\n",
    "total_dataset[:, 1] /= height_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset.shape\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "color = [(1*i, 1, 0) for i in total_dataset[:,2] ]\n",
    "ax1.scatter(total_dataset[:,0], total_dataset[:,1], c = color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(x, w, b):\n",
    "    pred = np.matmul(x, w.T) + b\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x, w, b, y):\n",
    "    loss = -y*hypothesis(x, w, b) + np.log(1 + np.exp(hypothesis(x, w, b))) #-y*h(x) + log(1+exp(h(x)))\n",
    "    cost = (1/m)*np.sum(loss)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(x, w, b, y):\n",
    "    dw = -(1/m)* np.sum( x*(y - sigmoid(hypothesis(x, w, b))) , axis = 0) # 1 x w_dim\n",
    "    db = -(1/m)* np.sum( y  - sigmoid(hypothesis(x, w, b)), axis = 0 )\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(x, w, b, y, alpha):\n",
    "    w = w - alpha*(derivative(x, w, b, y)[0]) # w := w + alpha * dw\n",
    "    b = b - alpha*(derivative(x, w, b, y)[1]) # b := b + alpha * db\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights and bias\n",
    "w = np.array([[0, 0]])\n",
    "b = 0\n",
    "\n",
    "x = total_dataset[:, :2] # x1, x2\n",
    "y = total_dataset[:, 2:3] # label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아래 두 개 cell을 반복하여 실행하며, 선형 분류기의 위치 변화를 관찰해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(_iter, x, w, b, y):\n",
    "    for i in range(_iter):\n",
    "        w, b = update(x, w, b, y, alpha=0.01)\n",
    "    print ('cost =',cost(x, w, b, y))\n",
    "    print ('w =',w)\n",
    "    print ('b =',b)\n",
    "    return w, b\n",
    "\n",
    "def visualize(w, b):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    color = [(1*i, 1, 0) for i in total_dataset[:,2] ]\n",
    "    ax1.scatter(total_dataset[:,0], total_dataset[:,1], c = color)\n",
    "\n",
    "    p1 = np.array([0, -b/w[0, 1]])\n",
    "    p2 = np.array([-b[0]/w[0, 0], 0]) # b has the shape as [1]\n",
    "    coefficients = np.polyfit([p1[0], p2[0]], [p1[1][0], p2[1]], 1)  \n",
    "    polynomial = np.poly1d(coefficients)\n",
    "    x_axis = np.linspace(0.5, 1.5)\n",
    "    y_axis = polynomial(x_axis)\n",
    "    ax1.set_ylim(0.5, 1.5)\n",
    "    ax1.plot(x_axis, y_axis)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    w, b = train(200, x, w, b, y)\n",
    "    visualize(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이런 문제는 어떨까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 클래스 A와 클래스 B를 생성함.\n",
    "m = 200\n",
    "class_A = np.random.normal(0, 1, [m, 2])\n",
    "label_A = np.ones([m, 1])\n",
    "\n",
    "class_B_x = np.random.normal(0, 2, [m, 1])\n",
    "class_B_y = 0.5*class_B_x**2 - 3\n",
    "\n",
    "class_B = np.concatenate([class_B_x, class_B_y], axis = 1)\n",
    "label_B = np.zeros([m, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 분포를 볼까요?\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.set_title('nonlinear distribution')\n",
    "ax1.set_xlabel('x1')\n",
    "ax1.set_ylabel('x2')\n",
    "\n",
    "ax1.set_xlim([-4,4])\n",
    "ax1.set_ylim([-4,4])\n",
    "\n",
    "ax1.scatter(class_A[:,0], class_A[:,1], c='red')\n",
    "\n",
    "ax1.scatter(class_B[:,0], class_B[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터의 shape을 볼까요?\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60000개 중 첫번째 데이터를 봅시다.\n",
    "img = x_train[0]\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값도 출력해봅시다.\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값도 출력해봅시다.\n",
    "vectorized = np.reshape(img, [28*28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이런 데이터도 잘 분류될 수 있을까?\n",
    "print(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
