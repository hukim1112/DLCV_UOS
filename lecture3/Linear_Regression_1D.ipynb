{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1) Linear Regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Synthetic data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of data to be created\n",
    "m = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수입력) x => 종속변수(정답) y \n",
    "x = np.random.randn(m, 1)\n",
    "y = 3 * x + np.random.rand(m, 1) * 5\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.title(\"The distribution of created dataset \")\n",
    "plt.xlabel(\"input x\")\n",
    "plt.ylabel(\"output y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로그래밍, 디버깅 과정에서 항상 데이터의 Shape을 보는 습관을 들이자.\n",
    "# 데이터의 수치는 보는 것은 코스트가 높은 행위이고, 생각보다 적은 정보를 준다.\n",
    "print (x.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights and bias\n",
    "w = 0\n",
    "b = 0\n",
    "\n",
    "# Linear model : y = w*x + b\n",
    "def hypothesis(x, w, b):\n",
    "    pred = np.multiply(w, x) + b\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용함수를 정의해봅시다! 학습에는 사용되지 않지만 학습과정에서 loss가 줄어드는지 확인해볼 수 있겠군요.\n",
    "\n",
    "loss = (1/2)*(hypothesis(x, w, b) - y)**2 # 1/2 * (h(x) - y)^2\n",
    "print(\"loss's shape? : \", loss.shape) #중간중간 정상적인 shape인지를 확인해줍시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 데이터에 대한 loss를 위해 총합을 구해봅시다.\n",
    "total_loss = (1/m)*np.sum(loss)\n",
    "print(\"loss's shape? : \", total_loss.shape)\n",
    "print(\"value of loss : \", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x, w, b, y):\n",
    "    loss = 1/2*(hypothesis(x, w, b) - y)**2 # loss = 1/2(h(x) - y)^2\n",
    "    total_loss = (1/m)*np.sum(loss)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost(x, w, b, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 학습에서는 gradient가 사용되죠?\n",
    "# 각 파라미터에 대한 gradient를 구해봅시다.\n",
    "# 자료에 gradient에 대한 수식이 있습니다.\n",
    "# d(cost)/dw =  (h(x) - y)(h(x))' = (h(x) - y)*x\n",
    "# d(cost)/db = (h(x) - y)(h(x))' = (h(x) -y)\n",
    "\n",
    "#shape 변화를 잘 트래킹하는 것이 요령입니다.\n",
    "print((hypothesis(x, w, b) - y).shape) # shape of (h(x) -y)\n",
    "print(x.shape) # shape of x\n",
    "print(((hypothesis(x, w, b) - y)*x).shape) # (h(x)-y)*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(x, w, b, y):\n",
    "    dw = np.sum(((hypothesis(x, w, b) - y)*x))\n",
    "    db = np.sum(((hypothesis(x, w, b) - y)))\n",
    "    return dw, db\n",
    "\n",
    "derivative(x,w,b,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(x, w, b, y, alpha):\n",
    "    dw, db = derivative(x, w, b, y)\n",
    "    w = w - alpha*dw # w := w + alpha * dw\n",
    "    b = b - alpha*db # b := b + alpha * db\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights and bias\n",
    "w = 0\n",
    "b = 0\n",
    "def visualize(w, b):\n",
    "    plt.scatter(x,y)\n",
    "    line_x = np.linspace(-4,4,100) # -4~4까지 100개의 값들\n",
    "    plt.plot(line_x, line_x * w + b) # -4~4까지 100개의 값에 대한 모델 출력값 = 선형모델이 만드는 선분으로 보일 것!\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번만 돌려봅시다.\n",
    "\n",
    "for i in range(10):\n",
    "    w, b = update(x,w,b,y, 0.001)\n",
    "    print(w, b)\n",
    "    visualize(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100번당 이미지를 출력합니다.\n",
    "\n",
    "for i in range(100):\n",
    "    w, b = update(x,w,b,y, 0.001)\n",
    "    if (i+1)%10 == 0:\n",
    "        visualize(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2) Linear Regression with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_x = x.reshape((100,1))\n",
    "reshaped_y = y.reshape((100,1))\n",
    "model = LinearRegression()\n",
    "model.fit(reshaped_x,reshaped_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('w =', model.coef_)\n",
    "print ('b =', model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
